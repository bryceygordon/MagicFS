diff --git a/src/librarian.rs b/src/librarian.rs
index c07b9e0..2ca5f33 100644
--- a/src/librarian.rs
+++ b/src/librarian.rs
@@ -2,11 +2,6 @@
 //!
 //! Watches physical directories, updates SQLite Index,
 //! ensures VFS consistency.
-//!
-//! Runs as a background thread (not async).
-//!
-//! CRITICAL RULE: Never blocks FUSE loop or Oracle.
-//! Completely isolated from Hollow Drive.
 
 use crate::state::SharedState;
 use crate::error::Result;
@@ -14,22 +9,76 @@ use notify::{RecommendedWatcher, Watcher, Event, EventKind, RecursiveMode};
 use std::sync::{Arc, Mutex, mpsc};
 use std::thread;
 use std::time::{Duration, Instant};
-use std::collections::HashMap;
+use std::collections::{HashMap, HashSet};
+use std::fs;
+use std::path::{Path, PathBuf};
+
+/// Manages ignore rules (like .gitignore)
+struct IgnoreManager {
+    rules: HashMap<PathBuf, HashSet<String>>,
+}
+
+impl IgnoreManager {
+    fn new() -> Self {
+        Self { rules: HashMap::new() }
+    }
+
+    fn load_rules_for_root(&mut self, root: &Path) {
+        let ignore_file = root.join(".magicfsignore");
+        let mut new_rules = HashSet::new();
+
+        new_rules.insert(".magicfsignore".to_string());
+        new_rules.insert(".magicfs".to_string());
+
+        if ignore_file.exists() {
+            tracing::info!("[Librarian] Loading ignore rules from: {}", ignore_file.display());
+            match fs::read_to_string(&ignore_file) {
+                Ok(content) => {
+                    for line in content.lines() {
+                        let rule = line.trim();
+                        if !rule.is_empty() && !rule.starts_with('#') {
+                            new_rules.insert(rule.to_string());
+                        }
+                    }
+                },
+                Err(e) => tracing::error!("[Librarian] Failed to read .magicfsignore: {}", e),
+            }
+        }
+        self.rules.insert(root.to_path_buf(), new_rules);
+    }
+
+    fn is_ignored(&self, abs_path: &Path, watch_roots: &[String]) -> bool {
+        let root = watch_roots.iter()
+            .map(Path::new)
+            .find(|root| abs_path.starts_with(root));
+
+        let root = match root {
+            Some(r) => r,
+            None => return false,
+        };
+
+        if let Some(rules) = self.rules.get(root) {
+            if let Ok(relative) = abs_path.strip_prefix(root) {
+                for component in relative.components() {
+                    let comp_str = component.as_os_str().to_string_lossy();
+                    if rules.contains(comp_str.as_ref()) {
+                        tracing::debug!("[Librarian] IGNORED '{}' (matched rule '{}')", abs_path.display(), comp_str);
+                        return true;
+                    }
+                }
+            }
+        }
+        false
+    }
+}
 
-/// The Librarian: background watcher thread
 pub struct Librarian {
-    /// Shared state for coordination
     pub state: SharedState,
-
-    /// Paths being watched
     pub watch_paths: Arc<Mutex<Vec<String>>>,
-
-    /// Handle to the watcher thread
     pub thread_handle: Option<thread::JoinHandle<()>>,
 }
 
 impl Librarian {
-    /// Create a new Librarian instance
     pub fn new(state: SharedState) -> Self {
         Self {
             state,
@@ -38,14 +87,6 @@ impl Librarian {
         }
     }
 
-    /// Check if a path should be ignored (dotfiles, hidden directories)
-    fn is_ignored_path(path: &std::path::Path) -> bool {
-        path.components().any(|component| {
-            component.as_os_str().to_string_lossy().starts_with('.')
-        })
-    }
-
-    /// Start the watcher thread
     pub fn start(&mut self) -> Result<()> {
         let watch_paths = Arc::clone(&self.watch_paths);
         let state = Arc::clone(&self.state);
@@ -56,47 +97,48 @@ impl Librarian {
 
         self.thread_handle = Some(handle);
         tracing::info!("[Librarian] Started watcher thread");
-
         Ok(())
     }
 
-    /// Add a path to the watch list
     pub fn add_watch_path(&self, path: String) -> Result<()> {
         let mut paths = self.watch_paths.lock().map_err(|_| crate::error::MagicError::State("Poisoned lock".into()))?;
-        paths.push(path);
-        tracing::info!("[Librarian] Added watch path");
+        
+        // Canonicalize to ensure notify works correctly with symlinks
+        let final_path = if let Ok(p) = fs::canonicalize(&path) {
+            p.to_string_lossy().to_string()
+        } else {
+            tracing::warn!("[Librarian] Failed to canonicalize path: {}. Using raw path.", path);
+            path
+        };
+        
+        paths.push(final_path.clone());
+        tracing::info!("[Librarian] Added watch path: {}", final_path);
         Ok(())
     }
 
-    /// Main watcher loop (runs on dedicated thread)
     fn watcher_loop(watch_paths: Arc<Mutex<Vec<String>>>, state: SharedState) {
         tracing::info!("[Librarian] Watcher loop started");
 
-        // Perform initial scan of existing files before setting up watcher
-        // This ensures files that already exist are indexed
-        {
-            let paths = match watch_paths.lock() {
-                Ok(guard) => guard.clone(),
-                Err(_) => {
-                    tracing::error!("[Librarian] Failed to lock watch_paths");
-                    Vec::new()
-                }
-            };
+        let paths_vec = match watch_paths.lock() {
+            Ok(guard) => guard.clone(),
+            Err(_) => Vec::new(),
+        };
 
-            tracing::info!("[Librarian] Starting initial file scan...");
-            for path in paths {
-                if let Err(e) = Self::scan_directory_for_files(&state, std::path::Path::new(&path)) {
-                    tracing::error!("[Librarian] Error scanning directory {}: {}", path, e);
-                } else {
-                    tracing::info!("[Librarian] Initial scan complete for: {}", path);
-                }
+        let mut ignore_manager = IgnoreManager::new();
+        for path_str in &paths_vec {
+            ignore_manager.load_rules_for_root(Path::new(path_str));
+        }
+
+        // Initial Scan
+        for path_str in &paths_vec {
+            let path = Path::new(path_str);
+            tracing::info!("[Librarian] Scanning root: {}", path_str);
+            if let Err(e) = Self::scan_directory_for_files(&state, path, &ignore_manager, &paths_vec) {
+                tracing::error!("[Librarian] Error scanning directory {}: {}", path_str, e);
             }
         }
 
-        // Phase 5 Step 1: Initialize notify watcher
         let (tx, rx) = mpsc::channel();
-
-        // Create a recommended watcher (platform-specific implementation)
         let mut watcher = match RecommendedWatcher::new(tx, notify::Config::default()) {
             Ok(w) => w,
             Err(e) => {
@@ -105,210 +147,143 @@ impl Librarian {
             }
         };
 
-        // Add all watch paths
-        {
-            let paths = match watch_paths.lock() {
-                Ok(guard) => guard.clone(),
-                Err(_) => {
-                    tracing::error!("[Librarian] Failed to lock watch_paths");
-                    Vec::new()
-                }
-            };
-
-            for path in paths {
-                if let Err(e) = watcher.watch(std::path::Path::new(&path), RecursiveMode::Recursive) {
-                    tracing::error!("[Librarian] Failed to watch path {}: {}", path, e);
-                } else {
-                    tracing::info!("[Librarian] Watching path: {}", path);
-                }
+        for path in &paths_vec {
+            tracing::info!("[Librarian] Watching: {}", path);
+            if let Err(e) = watcher.watch(Path::new(path), RecursiveMode::Recursive) {
+                tracing::error!("[Librarian] Failed to watch path {}: {}", path, e);
             }
         }
 
-        // Phase 5 Step 2: Debouncing for file events
-        // Wait for 500ms of quiet time before processing events
         let debounce_duration = Duration::from_millis(500);
-        let mut event_queue: HashMap<std::path::PathBuf, Event> = HashMap::new();
+        let mut event_queue: HashMap<PathBuf, Event> = HashMap::new();
         let mut last_activity = Instant::now();
 
-        // Main event loop
         loop {
-            // Receive file system events with timeout
             match rx.recv_timeout(Duration::from_millis(50)) {
-                Ok(event) => {
-                    // Collect events for debouncing
-                    if let Ok(event) = event {
+                Ok(event_res) => {
+                    if let Ok(event) = event_res {
+                        // DEBUG LOG: See if notify is even firing
+                        tracing::debug!("[Librarian] RAW EVENT: {:?}", event);
+                        
                         for path in &event.paths {
-                            // Store the most recent event for this path
                             event_queue.insert(path.clone(), event.clone());
                         }
                         last_activity = Instant::now();
                     }
                 }
                 Err(mpsc::RecvTimeoutError::Timeout) => {
-                    // Check if we've had a quiet period
                     if !event_queue.is_empty() && last_activity.elapsed() >= debounce_duration {
-                        // Process all queued events
+                        tracing::debug!("[Librarian] Processing debounced batch of {} events", event_queue.len());
                         let events_to_process = std::mem::take(&mut event_queue);
-                        for (_path, event) in events_to_process {
-                            if let Err(e) = Self::handle_file_event(&Ok(event), &state) {
+                        
+                        for (path, event) in events_to_process {
+                            if path.file_name().map_or(false, |n| n == ".magicfsignore") {
+                                tracing::info!("[Librarian] .magicfsignore modified. Reloading rules...");
+                                if let Some(root) = paths_vec.iter().map(Path::new).find(|r| path.starts_with(r)) {
+                                    ignore_manager.load_rules_for_root(root);
+                                }
+                                continue; 
+                            }
+                            if let Err(e) = Self::handle_file_event(&Ok(event), &state, &ignore_manager, &paths_vec) {
                                 tracing::error!("[Librarian] Error handling file event: {}", e);
                             }
                         }
-                        event_queue.clear();
                     }
                 }
                 Err(e) => {
                     tracing::error!("[Librarian] Watcher channel error: {}", e);
-                    // Try to recreate watcher on error
                     thread::sleep(Duration::from_millis(1000));
                 }
             }
         }
     }
 
-    /// Recursively scan directory for existing files to index
-    fn scan_directory_for_files(state: &SharedState, dir_path: &std::path::Path) -> Result<()> {
-        tracing::info!("[Librarian] Scanning directory: {}", dir_path.display());
-
+    fn scan_directory_for_files(state: &SharedState, dir_path: &Path, ignore_manager: &IgnoreManager, watch_roots: &[String]) -> Result<()> {
         if !dir_path.exists() {
-            tracing::warn!("[Librarian] Directory does not exist: {}", dir_path.display());
+            tracing::warn!("[Librarian] Scan path does not exist: {}", dir_path.display());
             return Ok(());
         }
 
-        if !dir_path.is_dir() {
-            tracing::warn!("[Librarian] Path is not a directory: {}", dir_path.display());
-            return Ok(());
-        }
+        let walker = walkdir::WalkDir::new(dir_path).into_iter();
+        
+        let filtered_walker = walker.filter_entry(|e| {
+            !ignore_manager.is_ignored(e.path(), watch_roots)
+        });
 
-        // Recursively walk the directory, skipping hidden files and directories
-        for entry in walkdir::WalkDir::new(dir_path) {
+        for entry in filtered_walker {
             match entry {
                 Ok(entry) => {
                     let path = entry.path();
-
-                    // Skip directory entries that start with '.' to prevent descending into them
-                    if entry.file_type().is_dir() && entry.file_name().to_string_lossy().starts_with('.') {
-                        tracing::debug!("[Librarian] Skipping hidden directory: {}", path.display());
-                        continue;
-                    }
-
-                    // Skip hidden files and directories (e.g., .obsidian, .git, .DS_Store)
-                    if entry.file_name().to_string_lossy().starts_with('.') || Self::is_ignored_path(path) {
-                        tracing::debug!("[Librarian] Skipping hidden file: {}", path.display());
-                        continue;
-                    }
-
                     if path.is_file() {
+                        if ignore_manager.is_ignored(path, watch_roots) {
+                            continue;
+                        }
                         let path_str = path.to_string_lossy().to_string();
-                        tracing::debug!("[Librarian] Found file to index: {}", path_str);
-
-                        // Add to indexing queue (same as event handling)
+                        tracing::debug!("[Librarian] Scan found file: {}", path_str);
+                        
                         let files_to_index = {
-                            let state_guard = state.read()
-                                .map_err(|_| crate::error::MagicError::State("Poisoned lock".into()))?;
+                            let state_guard = state.read().map_err(|_| crate::error::MagicError::State("Poisoned lock".into()))?;
                             Arc::clone(&state_guard.files_to_index)
                         };
-
-                        let mut queue = files_to_index.lock()
-                            .map_err(|_| crate::error::MagicError::State("Poisoned lock".into()))?;
+                        let mut queue = files_to_index.lock().map_err(|_| crate::error::MagicError::State("Poisoned lock".into()))?;
                         queue.push(path_str);
                     }
                 }
-                Err(e) => {
-                    tracing::warn!("[Librarian] Error walking directory: {}", e);
-                }
+                Err(e) => tracing::warn!("[Librarian] Error walking directory: {}", e),
             }
         }
-
-        tracing::info!("[Librarian] Directory scan complete: {}", dir_path.display());
         Ok(())
     }
 
-    /// Handle a file system event
-    fn handle_file_event(event: &std::result::Result<Event, notify::Error>, state: &SharedState) -> Result<()> {
+    fn handle_file_event(event: &std::result::Result<Event, notify::Error>, state: &SharedState, ignore_manager: &IgnoreManager, watch_roots: &[String]) -> Result<()> {
         match event {
             Ok(event) => {
-                tracing::debug!("[Librarian] File event: {:?} - {:?}", event.kind, event.paths);
-
-                // Phase 5 Step 2: Debouncing (will be added later)
-                // For now, process each event
-
-                // Handle different event types
                 match event.kind {
                     EventKind::Create(_) | EventKind::Modify(_) => {
                         for path in &event.paths {
-                            // Skip hidden files and directories (e.g., .obsidian, .git, .DS_Store)
-                            if Self::is_ignored_path(path) {
-                                tracing::debug!("[Librarian] Ignoring hidden file event: {:?}", path);
+                            if ignore_manager.is_ignored(path, watch_roots) {
                                 continue;
                             }
-
                             if path.is_file() {
                                 let path_str = path.to_string_lossy().to_string();
-                                tracing::info!("[Librarian] Queuing file for indexing: {}", path_str);
-
-                                // Phase 5 Step 6: Add to indexing queue
-                                // Oracle will process this asynchronously
+                                tracing::info!("[Librarian] Queuing file for index: {}", path_str);
+                                
                                 let files_to_index = {
-                                    let state_guard = state.read()
-                                        .map_err(|_| crate::error::MagicError::State("Poisoned lock".into()))?;
+                                    let state_guard = state.read().map_err(|_| crate::error::MagicError::State("Poisoned lock".into()))?;
                                     Arc::clone(&state_guard.files_to_index)
                                 };
-
-                                let mut queue = files_to_index.lock()
-                                    .map_err(|_| crate::error::MagicError::State("Poisoned lock".into()))?;
+                                let mut queue = files_to_index.lock().map_err(|_| crate::error::MagicError::State("Poisoned lock".into()))?;
                                 queue.push(path_str);
                             }
                         }
                     }
                     EventKind::Remove(_) => {
                         for path in &event.paths {
+                            if ignore_manager.is_ignored(path, watch_roots) {
+                                continue;
+                            }
                             let path_str = path.to_string_lossy().to_string();
                             tracing::info!("[Librarian] Queuing file for deletion: {}", path_str);
-
-                            // CRITICAL FIX: Librarian is "The Hands" (observer), not the executioner.
-                            // We must NOT delete from registry here - let Oracle handle it atomically.
-                            // This prevents the "Amnesiac Deletion" race condition where:
-                            // 1. Librarian deletes from file_registry
-                            // 2. Oracle tries to get file_id but gets None
-                            // 3. Embedding in vec_index becomes orphaned forever
-
+                            
                             let files_to_index = {
-                                let state_guard = state.read()
-                                    .map_err(|_| crate::error::MagicError::State("Poisoned lock".into()))?;
+                                let state_guard = state.read().map_err(|_| crate::error::MagicError::State("Poisoned lock".into()))?;
                                 Arc::clone(&state_guard.files_to_index)
                             };
-
-                            let mut queue = files_to_index.lock()
-                                .map_err(|_| crate::error::MagicError::State("Poisoned lock".into()))?;
-
-                            // Push DELETE marker - Oracle will handle atomic cleanup:
-                            // 1. Get file_id from file_registry
-                            // 2. Delete embedding from vec_index
-                            // 3. Delete file from file_registry
+                            let mut queue = files_to_index.lock().map_err(|_| crate::error::MagicError::State("Poisoned lock".into()))?;
                             queue.push(format!("DELETE:{}", path_str));
                         }
                     }
-                    _ => {
-                        // Other event types (metadata changes, etc.)
-                        tracing::debug!("[Librarian] Other event: {:?}", event.kind);
-                    }
+                    _ => {}
                 }
             }
-            Err(e) => {
-                tracing::error!("[Librarian] Event error: {}", e);
-            }
+            Err(e) => tracing::error!("[Librarian] Event error: {}", e),
         }
-
         Ok(())
     }
 
-    /// Stop the watcher thread
     pub fn stop(&mut self) -> Result<()> {
         if let Some(handle) = self.thread_handle.take() {
-            handle.join()
-                .map_err(|_| crate::error::MagicError::State("Failed to join watcher thread".into()))?;
-            tracing::info!("[Librarian] Stopped");
+            handle.join().map_err(|_| crate::error::MagicError::State("Failed to join watcher thread".into()))?;
         }
         Ok(())
     }
@@ -318,8 +293,6 @@ impl Drop for Librarian {
     fn drop(&mut self) {
         if let Some(handle) = &self.thread_handle {
             handle.thread().unpark();
-            // Note: We can't join here without blocking
-            // In a real implementation, we'd use a proper shutdown mechanism
         }
     }
-}
\ No newline at end of file
+}
diff --git a/src/oracle.rs b/src/oracle.rs
index 49a6b10..691ffd8 100644
--- a/src/oracle.rs
+++ b/src/oracle.rs
@@ -156,8 +156,11 @@ impl Oracle {
                 let state_guard = state.read().map_err(|_| MagicError::State("Poisoned lock".into())).unwrap();
                 let mut files_to_index_lock = state_guard.files_to_index.lock().unwrap_or_else(|e| e.into_inner());
                 
-                // Only take files if we haven't processed them to avoid loops
-                // Note: In production we'd want a more robust queue system
+                // DEBUG LOGGING
+                if !files_to_index_lock.is_empty() {
+                    tracing::debug!("[Oracle] Found {} files in queue", files_to_index_lock.len());
+                }
+
                 files_to_index_lock.drain(..)
                     .filter(|file| !processed_files.contains(file))
                     .collect()
diff --git a/tests/__pycache__/common.cpython-313.pyc b/tests/__pycache__/common.cpython-313.pyc
new file mode 100644
index 0000000..c3c7640
Binary files /dev/null and b/tests/__pycache__/common.cpython-313.pyc differ
diff --git a/tests/cases/test_01_indexing.py b/tests/cases/test_01_indexing.py
new file mode 100644
index 0000000..d37e7be
--- /dev/null
+++ b/tests/cases/test_01_indexing.py
@@ -0,0 +1,13 @@
+from common import MagicTest
+
+test = MagicTest()
+print("--- TEST 01: Dynamic Indexing ---")
+
+# 1. Create file dynamically
+test.create_file("game.py", "import snake\nprint('hiss')")
+
+# 2. Wait for Librarian -> Oracle pipeline
+test.wait_for_indexing("game.py")
+
+# 3. Assert
+test.assert_file_indexed("game.py")
diff --git a/tests/cases/test_02_dotfiles.py b/tests/cases/test_02_dotfiles.py
new file mode 100644
index 0000000..aef0c31
--- /dev/null
+++ b/tests/cases/test_02_dotfiles.py
@@ -0,0 +1,24 @@
+from common import MagicTest
+import time
+
+test = MagicTest()
+print("--- TEST 02: Dynamic Ignore Rules ---")
+
+# 1. Set up ignore rules
+# We must explicitly add .git if we want to test that it gets ignored!
+test.add_ignore_rule("secrets")
+test.add_ignore_rule(".git")
+
+# 2. Create ignored content
+test.create_file("secrets/password.txt", "super_secret")
+test.create_file(".git/config", "repo_config")
+
+# 3. Create normal content to ensure system is still working
+# This acts as a "barrier" to ensure the previous file events have been processed
+test.create_file("public/readme.md", "# Public Info")
+test.wait_for_indexing("readme.md")
+
+# 4. Assertions
+test.assert_file_not_indexed("password.txt")
+test.assert_file_not_indexed("config") 
+test.assert_file_indexed("readme.md")
diff --git a/tests/cases/test_03_search.py b/tests/cases/test_03_search.py
new file mode 100644
index 0000000..7c826d8
--- /dev/null
+++ b/tests/cases/test_03_search.py
@@ -0,0 +1,15 @@
+from common import MagicTest
+
+test = MagicTest()
+print("--- TEST 03: Semantic Search ---")
+
+# 1. Create content
+# This creates a NEW directory 'projects'. 
+# The updated create_file has a tiny sleep to help notify catch up.
+test.create_file("projects/ai.rs", "// This is a rust vector search implementation")
+
+# 2. Wait for indexing (Hard Fails now if missed)
+test.wait_for_indexing("ai.rs")
+
+# 3. Search
+test.search_fs("vector search", "ai.rs")
diff --git a/tests/common.py b/tests/common.py
new file mode 100644
index 0000000..308ea0b
--- /dev/null
+++ b/tests/common.py
@@ -0,0 +1,97 @@
+import sqlite3
+import os
+import time
+import sys
+import shutil
+
+class MagicTest:
+    def __init__(self):
+        if len(sys.argv) < 4:
+            print("Usage: python test.py <db_path> <mount_point> <watch_dir>")
+            sys.exit(1)
+        
+        self.db_path = sys.argv[1]
+        self.mount_point = sys.argv[2]
+        self.watch_dir = sys.argv[3]
+
+    def create_file(self, rel_path, content):
+        """Creates a file in the watch directory."""
+        full_path = os.path.join(self.watch_dir, rel_path)
+        dir_name = os.path.dirname(full_path)
+        
+        # If we are creating a new directory, give the watcher a split second
+        # to attach to it before creating the file. This mimics real user speed.
+        if not os.path.exists(dir_name):
+            os.makedirs(dir_name, exist_ok=True)
+            time.sleep(0.2) 
+
+        with open(full_path, "w") as f:
+            f.write(content)
+        print(f"[Setup] Created file: {rel_path}")
+
+    def add_ignore_rule(self, rule):
+        """Appends a rule to .magicfsignore."""
+        ignore_path = os.path.join(self.watch_dir, ".magicfsignore")
+        with open(ignore_path, "a") as f:
+            f.write(f"\n{rule}\n")
+        print(f"[Setup] Added ignore rule: {rule}")
+        time.sleep(0.5)
+
+    def wait_for_indexing(self, filename_substr, timeout=5):
+        """Polls DB until file appears."""
+        print(f"[Wait] Waiting for '{filename_substr}' to be indexed...")
+        start = time.time()
+        while time.time() - start < timeout:
+            if self.check_file_in_db(filename_substr):
+                print(f"✅ Found '{filename_substr}' in index.")
+                return True
+            time.sleep(0.1)
+        
+        print(f"❌ Timeout waiting for {filename_substr}")
+        sys.exit(1) # HARD FAIL to preserve logs
+
+    def check_file_in_db(self, filename_substr):
+        try:
+            conn = sqlite3.connect(self.db_path)
+            cursor = conn.cursor()
+            cursor.execute("SELECT abs_path FROM file_registry")
+            files = [row[0] for row in cursor.fetchall()]
+            conn.close()
+            return any(filename_substr in f for f in files)
+        except:
+            return False
+
+    def assert_file_indexed(self, filename_substr):
+        if self.check_file_in_db(filename_substr):
+            print(f"✅ Found '{filename_substr}' in index.")
+            return True
+        print(f"❌ FAILURE: '{filename_substr}' missing from index.")
+        sys.exit(1)
+
+    def assert_file_not_indexed(self, filename_substr):
+        time.sleep(1) 
+        if self.check_file_in_db(filename_substr):
+            print(f"❌ FAILURE: Should ignore '{filename_substr}', but found it in DB.")
+            sys.exit(1)
+        print(f"✅ Correctly ignored '{filename_substr}'.")
+        return True
+
+    def search_fs(self, query, expected_filename, retries=10):
+        search_path = os.path.join(self.mount_point, "search", query)
+        print(f"[*] Searching for '{query}'...")
+        
+        for i in range(retries):
+            try:
+                if os.path.exists(search_path):
+                    results = os.listdir(search_path)
+                    if any(expected_filename in r for r in results):
+                        print(f"✅ Found '{expected_filename}' in search results.")
+                        return True
+            except OSError:
+                pass 
+            
+            print(f"    ... waiting for Oracle (attempt {i+1}/{retries})")
+            time.sleep(0.5)
+            
+        print(f"❌ FAILURE: Search for '{query}' failed.")
+        sys.exit(1)
diff --git a/tests/run_suite.sh b/tests/run_suite.sh
index 66237ab..05b1e19 100755
--- a/tests/run_suite.sh
+++ b/tests/run_suite.sh
@@ -8,117 +8,93 @@ DB_PATH="/tmp/.magicfs/index.db"
 BINARY="./target/debug/magicfs"
 LOG_FILE="tests/magicfs.log"
 
-# Colors
-GREEN='\033[0;32m'
-RED='\033[0;31m'
-NC='\033[0m'
-
-# Disable job control messages (prevents "Killed..." output)
-set +m
-
-# Force sanity immediately
+# Force terminal sanity immediately
 stty sane
 
-echo -e "${GREEN}=== MagicFS Test Suite ===${NC}"
-
-# 0. Sudo Refresh
-echo "Acquiring sudo privileges..."
-if ! sudo -v; then
-    echo -e "${RED}Sudo authentication failed.${NC}"
-    exit 1
-fi
-
-# Keep sudo alive in background, silenced
-( while true; do sudo -v; sleep 60; done; ) > /dev/null 2>&1 &
-SUDO_KEEPALIVE_PID=$!
-disown $SUDO_KEEPALIVE_PID # Tell shell to ignore this job
-
-# 1. Cleanup Function
+# Setup/Cleanup Logic
 cleanup() {
-    # Mute any remaining job noise
-    set +m 
-    
+    set +e
     echo ""
     echo "Cleaning up..."
     
-    # Kill sudo keepalive silently
-    kill $SUDO_KEEPALIVE_PID 2>/dev/null || true
-    
-    # Kill magicfs aggressively
-    # We use pkill -9 to ensure it dies immediately
-    sudo pkill -9 -f "magicfs" > /dev/null 2>&1 || true
+    # Kill keepalive if it exists
+    if [ ! -z "$SUDO_KEEPALIVE_PID" ]; then
+        kill $SUDO_KEEPALIVE_PID 2>/dev/null
+    fi
+
+    # Kill magicfs
+    sudo pkill -9 -f "magicfs" > /dev/null 2>&1
     
-    # Lazy unmount if needed
+    # Unmount
     if mount | grep -q "$MOUNT_POINT"; then
-        sudo umount -l "$MOUNT_POINT" > /dev/null 2>&1 || true
+        sudo umount -l "$MOUNT_POINT" > /dev/null 2>&1
     fi
-    
-    # Remove test artifacts
+
+    # Remove data
     if [ -f "$DB_PATH" ]; then
         sudo rm -f "$DB_PATH"
     fi
     sudo rm -rf "$MOUNT_POINT"
     rm -rf "$WATCH_DIR"
-
-    # CRITICAL: Restore terminal sanity as the FINAL step of cleanup
+    
+    # FIX: Force terminal to behave correctly after cleanup
     stty sane
 }
-
 trap cleanup EXIT
 
-# Run pre-cleanup to kill zombies from previous runs
-cleanup
+# 0. Sudo Refresh (Keep alive in background)
+echo "Acquiring sudo privileges..."
+sudo -v
+( while true; do sudo -v; sleep 60; done; ) > /dev/null 2>&1 &
+SUDO_KEEPALIVE_PID=$!
+
+# 1. Clean & Prepare
+cleanup # Run cleanup once to ensure clean slate
+mkdir -p "$MOUNT_POINT"
+mkdir -p "$WATCH_DIR"
 
 # 2. Build
-echo "Building MagicFS..."
+echo "Building..."
 if ! cargo build --quiet; then
-    echo -e "${RED}Build failed.${NC}"
     exit 1
 fi
 
-# 3. Setup Data
-mkdir -p "$MOUNT_POINT"
-mkdir -p "$WATCH_DIR"
-mkdir -p "$WATCH_DIR/.git"
-mkdir -p "$WATCH_DIR/.obsidian"
-mkdir -p "$WATCH_DIR/Projects"
-
-echo "This is a python script about snake games." > "$WATCH_DIR/game.py"
-echo "Rust is a systems programming language." > "$WATCH_DIR/Projects/main.rs"
-echo "Secret git config" > "$WATCH_DIR/.git/config"
-echo "Obsidian workspace settings" > "$WATCH_DIR/.obsidian/workspace.json"
-
-# 4. Run MagicFS
-echo -e "${GREEN}Launching MagicFS... (Logs -> $LOG_FILE)${NC}"
-sudo RUST_LOG=info $BINARY "$MOUNT_POINT" "$WATCH_DIR" > "$LOG_FILE" 2>&1 &
+# 3. Launch MagicFS
+# FIX: Use RUST_LOG=debug so we can see Librarian events in the logs
+echo "Launching MagicFS (Debug Mode)..."
+sudo RUST_LOG=debug $BINARY "$MOUNT_POINT" "$WATCH_DIR" > "$LOG_FILE" 2>&1 &
 MAGIC_PID=$!
-disown $MAGIC_PID # Tell shell to ignore this job
 
-echo "Waiting for system to mount and index (5 seconds)..."
-sleep 5
+# Wait for startup
+sleep 3
 
-# Check if alive (using pgrep because we disowned it)
 if ! pgrep -f "$BINARY" > /dev/null; then
-    echo -e "${RED}MagicFS died! Dumping log:${NC}"
+    echo "MagicFS died on startup. Check logs."
     cat "$LOG_FILE"
     exit 1
 fi
 
-# 5. Verify
-echo -e "${GREEN}Running Verification Logic...${NC}"
+# 4. Run Tests
+export PYTHONPATH=$PYTHONPATH:$(pwd)/tests
 
-set +e # Turn off exit-on-error to handle python failure gracefully
-python3 tests/verify.py "$DB_PATH" "$MOUNT_POINT"
-TEST_EXIT_CODE=$?
-set -e
+# Fix terminal again before tests just in case
+stty sane
 
-if [ $TEST_EXIT_CODE -eq 0 ]; then
-    echo -e "${GREEN}✅ ALL TESTS PASSED${NC}"
-else
-    echo -e "${RED}❌ TESTS FAILED. Dumping MagicFS Log:${NC}"
-    echo "---------------------------------------------------"
-    cat "$LOG_FILE"
-    echo "---------------------------------------------------"
-fi
+for test_file in tests/cases/*.py; do
+    echo -e "\n>>> Running: $(basename "$test_file")"
+    
+    # Run test
+    set +e
+    python3 "$test_file" "$DB_PATH" "$MOUNT_POINT" "$WATCH_DIR"
+    RESULT=$?
+    set -e
+    
+    if [ $RESULT -ne 0 ]; then
+        echo "❌ TEST FAILED"
+        echo "--- LOG DUMP (Last 50 lines) ---"
+        tail -n 50 "$LOG_FILE"
+        exit 1
+    fi
+done
 
-exit $TEST_EXIT_CODE
+echo -e "\n✅ ALL TESTS PASSED"
diff --git a/tests/verify.py b/tests/verify.py
deleted file mode 100644
index d0e3840..0000000
--- a/tests/verify.py
+++ /dev/null
@@ -1,97 +0,0 @@
-import sqlite3
-import sys
-import os
-import time
-
-DB_PATH = sys.argv[1]
-MOUNT_POINT = sys.argv[2]
-
-def check_database():
-    print(f"[*] Checking Database at {DB_PATH}...", flush=True)
-    
-    conn = sqlite3.connect(DB_PATH)
-    cursor = conn.cursor()
-    
-    cursor.execute("SELECT abs_path FROM file_registry")
-    files = [row[0] for row in cursor.fetchall()]
-    conn.close()
-    
-    print(f"    Found {len(files)} indexed files.", flush=True)
-    
-    # 1. Assert Visible files exist
-    if not any("game.py" in f for f in files):
-        print("❌ game.py missing from index", flush=True)
-        return False
-        
-    if not any("main.rs" in f for f in files):
-        print("❌ main.rs missing from index", flush=True)
-        return False
-    
-    # 2. Assert Hidden files check
-    dotfiles_present = any(".git" in f or ".obsidian" in f for f in files)
-    
-    if dotfiles_present:
-        print("⚠️  WARNING: Dotfiles/Hidden files were found in the index (Feature not implemented yet).", flush=True)
-    else:
-        print("✅  Dotfiles correctly ignored.", flush=True)
-
-    return True
-
-def check_fuse_search():
-    print(f"[*] Checking FUSE Search at {MOUNT_POINT}...", flush=True)
-    
-    search_query = "python"
-    search_path = os.path.join(MOUNT_POINT, "search", search_query)
-    
-    # RETRY LOGIC for Async Oracle
-    # The first access might return EAGAIN or fail because results aren't ready
-    max_retries = 5
-    found = False
-    results = []
-
-    for i in range(max_retries):
-        try:
-            if os.path.exists(search_path):
-                results = os.listdir(search_path)
-                # If we get results, we are good
-                if results:
-                    found = True
-                    break
-            else:
-                # Trigger the lookup
-                try:
-                    os.listdir(search_path)
-                except OSError:
-                    pass # Expected failure on first try if returning EAGAIN
-        except Exception as e:
-            pass
-            
-        print(f"    ... attempt {i+1}: Waiting for Oracle...", flush=True)
-        time.sleep(1) # Wait for Oracle to compute embeddings
-
-    if not found and not results:
-        print(f"❌ Search directory {search_path} empty or not found after {max_retries} attempts", flush=True)
-        return False
-        
-    print(f"    Search for '{search_query}' returned: {results}", flush=True)
-    
-    # Check if we got the expected file (game.py should score high for 'python')
-    if not any("game.py" in r for r in results):
-        print("❌ Search results did not contain 'game.py'", flush=True)
-        return False
-        
-    print("✅ Search returned results.", flush=True)
-    return True
-
-if __name__ == "__main__":
-    try:
-        if not check_database():
-            sys.exit(1)
-        
-        if not check_fuse_search():
-            sys.exit(1)
-            
-        sys.exit(0)
-    except Exception as e:
-        print(f"❌ Critical Error: {e}", flush=True)
-        sys.exit(1)
